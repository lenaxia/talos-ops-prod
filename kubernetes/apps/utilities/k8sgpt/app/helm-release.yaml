---
# yaml-language-server: $schema=https://kubernetes-schemas.thesteamedcrab.com/helmrelease_v2.json
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name:  k8sgpt-operator
  namespace: utilities
spec:
  interval: 30m
  chart:
    spec:
      chart: k8sgpt-operator
      version: 0.2.24
      sourceRef:
        kind: HelmRepository
        name: k8sgpt-charts
        namespace: flux-system

  maxHistory: 3

  install:
    remediation:
      retries: 3

  upgrade:
    cleanupOnFail: true
    remediation:
      retries: 3

  uninstall:
    keepHistory: false

  values:

    ## Optional enable distributed cache
    interplex:
      enabled: false

    serviceMonitor:
      enabled: false
      additionalLabels: {}
      # The namespace where Prometheus expects to find the serviceMonitor
      # namespace: ""
    grafanaDashboard:
      enabled: false
      # The namespace where Grafana expects to find the dashboard
      # namespace: ""
      folder:
        annotation: grafana_folder
        name: ai
      label:
        key: grafana_dashboard
        value: "1"
      # create GrafanaDashboard custom resource referencing to the configMap.
      # according to https://grafana-operator.github.io/grafana-operator/docs/examples/dashboard_from_configmap/readme/
      grafanaOperator:
        enabled: false
        matchLabels:
          dashboards: "grafana"
    controllerManager:
      # Additional annotations to add to the controller manager deployment
      annotations: {}
      kubeRbacProxy:
        containerSecurityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
        image:
          repository: quay.io/brancz/kube-rbac-proxy
          tag: v0.19.1
        resources:
          limits:
            cpu: 500m
            memory: 256Mi
          requests:
            cpu: 5m
            memory: 64Mi
      manager:
        sinkWebhookTimeout: 30s
        enableResultLogging: false
        containerSecurityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
        image:
          repository: ghcr.io/k8sgpt-ai/k8sgpt-operator
          tag: v0.2.24  # x-release-please-version
        resources:
          limits:
            cpu: 1000m
            memory: 1024Mi
          requests:
            cpu: 10m
            memory: 128Mi
      replicas: 1
      ## Node labels for pod assignment
      ## ref: https://kubernetes.io/docs/user-guide/node-selection/
      #
      nodeSelector: {}
      podSecurityContext:
        runAsNonRoot: true
        # Set securityContext.runAsUser/runAsGroup if necessary. Values below were taken from https://github.com/k8sgpt-ai/k8sgpt-operator/blob/main/Dockerfile
        # runAsUser: 65532
        # runAsGroup: 65532
    kubernetesClusterDomain: cluster.local
    metricsService:
      ports:
      - name: https
        port: 8443
        protocol: TCP
        targetPort: https
      type: ClusterIP
