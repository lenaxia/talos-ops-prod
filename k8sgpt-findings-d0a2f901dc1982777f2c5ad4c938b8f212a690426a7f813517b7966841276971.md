# k8sgpt Finding: MutatingWebhookConfiguration Pointing to Inactive Pods

## Finding Details

- **Kind:** MutatingWebhookConfiguration
- **Resource:** inteldeviceplugins-mutating-webhook-configuration
- **Namespace:** kube-system
- **Parent:** <none>
- **k8sgpt fingerprint:** `d0a2f901dc1982777f2c5ad4c938b8f212a690426a7f813517b7966841276971`

## Summary

k8sgpt reported that the MutatingWebhook `mnpudeviceplugin.kb.io` is pointing to inactive receiver pods. Upon investigation, this appears to be a false positive - the webhook configuration is correct and functioning properly.

## Investigation Findings

### Webhook Configuration
- The MutatingWebhookConfiguration `inteldeviceplugins-mutating-webhook-configuration` contains 10 webhooks including `mnpudeviceplugin.kb.io`
- All webhooks correctly point to Service `inteldeviceplugins-webhook-service` in namespace `kube-system`

### Service and Endpoints
- Service `inteldeviceplugins-webhook-service` (ClusterIP: 10.96.132.57:443) is correctly configured
- Service selector: `control-plane: controller-manager`
- Endpoint correctly points to active pod `10.69.5.77:9443`

### Pod Status
- Active pod: `inteldeviceplugins-controller-manager-c5b6f7964-krpsb` (Running, 0 restarts, 9 days old)
- Inactive pods flagged by k8sgpt:
  - `inteldeviceplugins-controller-manager-6bd5cc95bf-2kzwj` (Completed, 5 restarts, 70 days old)
  - `inteldeviceplugins-controller-manager-6bd5cc95bf-r9kzv` (Completed, 6 restarts, 79 days old)

### Deployment Status
- Deployment `inteldeviceplugins-controller-manager` is healthy with 1 ready replica
- Current revision: 4 (ReplicaSet `c5b6f7964`)
- RollingUpdate strategy with 25% maxSurge and maxUnavailable
- revisionHistoryLimit: 10

### Flux/Helm State
- HelmRelease `intel-device-plugin-operator` is in-sync and ready
- Chart: `intel-device-plugins-operator` version 0.34.1
- Last sync: successful
- No errors in Flux logs

## Root Cause

The k8sgpt finding appears to be a false positive. The tool detected that:
1. There are multiple pods matching the service selector `control-plane: controller-manager`
2. Some of these pods are in inactive state (Completed)
3. This triggered the "pointing to inactive receiver pods" alert

However, in reality:
- The webhook correctly points to a Service, not directly to pods
- The Service's endpoints are correctly managed by Kubernetes and only include the active running pod
- The inactive completed pods are not receiving webhook traffic

## Recommendation

**No GitOps changes required.** The webhook configuration is correct.

**Recommended operational actions:**
1. Clean up old completed pods: `kubectl delete pod <pod-name> -n kube-system`
2. Optionally reduce revisionHistoryLimit in HelmRelease values if old ReplicaSets are not needed

## Confidence

**Low** - This is likely a false positive. The webhook infrastructure is correctly configured and functioning.

## Notes

- Readiness probe timeouts observed in pod events (1860 times over 9 days) should be investigated separately
- TLS handshake errors in logs suggest intermittent connectivity issues
- No evidence of actual webhook failures affecting the cluster
